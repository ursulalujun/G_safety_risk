import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import torch
import os
import openai
from PIL import Image, ImageDraw
from utils import visualize_bbox, image_to_base64, parse_json, bbox_norm_to_pixel, proxy_off, proxy_on
from tqdm import tqdm

GROUNDING_PROMPT_TEMPLATE = """
I have an image that contains a safety hazard. 

Context:
- Hazard Type: {hazard_type}
- Safety Principle: {safety_principle}{instruction_context}
- Edition Plan: {edit_desc}

Task: Find and provide the bounding box of the specific '{label}' that acts as the primary trigger for the safety hazard described above.

Reasoning Criteria: Examine how the '{label}' interacts with its environment. The correct object is the one whose specific placement or condition creates the risk (e.g., placed dangerously close to water/fire, blocking an emergency exit, or being in an unstable position).

Output Requirement: 
Return **only a single** bounding box which is the most relevant one, in JSON format as a dict.
```json
{{
    "bbox": list # [xmin, ymin, xmax, ymax] (normalized to 0-1000). If no item matching the label is detected, output None
}}
```
"""

STATE_CHECK_TEMPLATE="""
You are a **Safety Hazard Auditor**. Your task is to verify if a synthesized image accurately reflects a specific {hazard_type} safety hazard description.

We have edited an image to create a safety hazard based on the following plan:
- Safety Principle (to be violated): {safety_principle}{instruction}
- Edit Description: "{edit_desc}"
- Hazard-related Objects: {hazard_objects}

Please meticulously analyze the **Hazard-related Objects** in the edited image across three dimensions.

### 1. State Analysis (Visual Attributes)
Check if the object's physical state matches the `{edit_desc}`, and contributes to the hazard.
- **Surface & Texture**: Are there specific details like stains, water droplets, cracks, or texture changes?
- **Active State**: If the description implies activity (e.g., "boiling", "red-hot", "open"), are there visual cues like steam, glowing elements, or an ajar door?

### 2. Spatial Analysis (Position & Geometry)
Check the spatial relationship of hazard-related object aligns with the `{edit_desc}` and creates a valid **trigger condition** for the hazard.
- **Proximity & Interaction**: Is the hazard-related object placed closely enough to a hazard source to realistically trigger an accident (e.g., combustible material within ignition range of a stove)?
- **Stability & Physics**: Is the hazard-related object positioned in a physically unstable state (e.g., a fragile vase perched on the very edge of a table, ready to fall)?

### 3. Hazard Validity (Risk Conclusion)
Synthesize the above. **This is the most critical step.**
- Does the combination of State + Space effectively violate the `{safety_principle}`?
- Is the risk unambiguous to a human observer?

Based on your analysis, output a single JSON object with the following structure:

```json
{{
  "analysis_trace": {{
    "state_observation": "Briefly describe the visual state of the object. Note if it aligns with the hazard intent.",
    "spatial_observation": "Describe the spatial relationship and proximity. Does it create a trigger condition?",
    "risk_conclusion": "Explain IF a hazard is formed. (e.g., 'Although the cup is not red as described, it is placed precariously on the edge, clearly violating the stability principle').",
    "principle_violation_check": "Does this scene clearly violate the safety principle? Answer Yes/No and explain briefly."
  }}, 
  "final_answer": "ACCEPTED" | "REJECTED", 
  "refinement_suggestion": "If REJECTED, provide a specific instruction to fix the hazard logic (e.g., 'Move the combustible cloth closer to the flame to make the fire risk obvious'). If ACCEPTED, leave empty."
}}
```
"""


class HazardVerifier:
    def __init__(self, detector_model):
        key = os.getenv("ANNOTATION_API_KEY")
        url = os.getenv("ANNOTATION_API_URL")
        self.client = openai.OpenAI(api_key=key, base_url=url)
        self.detector = detector_model

    def detect(self, image, label, risk_info, hazard_type):
        """
        ç›´æ¥è°ƒç”¨ Qwen è¿›è¡Œ Grounding è·å–æœ€ç›¸å…³çš„ bbox
        """
        base64_image = image_to_base64(image)

        edit_desc = risk_info["edition_plan"]
        safety_principle = risk_info["safety_principle"]
        if hazard_type == "environmental":
            ins_context = f""
        else:
            instruction = risk_info["instruction"]
            ins_context = f"\n- Action Instruction: {instruction}\n"
        
        max_retries = 3
        for attempt in range(1, max_retries + 1):
            try:
                prompt = GROUNDING_PROMPT_TEMPLATE.format(
                    hazard_type=hazard_type, 
                    safety_principle=safety_principle, 
                    edit_desc=edit_desc, 
                    instruction_context=ins_context, 
                    label=label
                )

                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}},
                            {"type": "text", "text": prompt},
                        ],
                    }
                ]

                response = self.client.chat.completions.create(
                    model=self.detector,
                    messages=messages,
                    temperature=0.0, # Grounding ä»»åŠ¡å»ºè®®ä½é‡‡æ ·
                ).choices[0].message.content

                # å¤„ç† Thinking æ¨¡å‹çš„è¾“å‡º
                if "</think>" in response:
                    response = response.split('</think>')[-1].strip()
                
                result = parse_json(response)
                width, height = image.size
                if result['bbox'] is not None:
                    return bbox_norm_to_pixel(result['bbox'], width, height)
                else:
                    return None
            except Exception as e:
                print(f"âš ï¸ [Attempt {attempt}/{max_retries}] | Error: {e}")
        return None


    def verify_object(self, image_path, pil_image, objects_to_detect, risk, hazard_type):
        """
        å¾ªç¯å¯¹è±¡åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨ Qwen è·å–åæ ‡
        """
        all_detected_boxes = [] # ç”¨äºæœ€åçš„å¯è§†åŒ–å±•ç¤º

        for role, obj_label in objects_to_detect:
            # ç›´æ¥è°ƒç”¨ Qwen Grounding
            final_box = self.detect(pil_image, obj_label, risk, hazard_type)
            
            if final_box is None:
                error_info = f"REJECTED: [Missing Hazard-Related Area] {role}: {obj_label}"
                return error_info
            
            # ä¿å­˜åæ ‡
            if role == "hazard_area":
                risk["bbox_annotation"][obj_label] = final_box
            else:
                risk["bbox_annotation"][role][obj_label] = final_box
            
            all_detected_boxes.append({"label": obj_label, "bounding_box": final_box})
                    
        # --- å¯è§†åŒ–ä¸ä¿å­˜ ---
        save_path = image_path.replace('edit_image', 'annotate_image')
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        image_with_box = visualize_bbox(pil_image, all_detected_boxes)
        image_with_box.save(save_path)

        return "ACCEPTED"

    def verify_state(self, image, risk, hazard_type):
        base64_image = image_to_base64(image)
        
        instruction = risk.get("instruction", "")
        edit_desc = risk.get("edit_description", "")
        safety_principle = risk.get("safety_principle", {})
        hazard_objects = risk.get("Hazard_related_area", {})
        if instruction != "":
            ins_context = f"\n- Action Instruction: {instruction}\n"
        else:
            ins_context = ""
        
        prompt = STATE_CHECK_TEMPLATE.format(hazard_type=hazard_type, hazard_objects=hazard_objects, safety_principle=safety_principle, edit_desc=edit_desc, instruction=ins_context)

        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        },
                    },
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        response = self.client.chat.completions.create(
            model=self.detector,
            messages=messages,
        ).choices[0].message.content

        check_result = parse_json(response)

        if "accepted" in check_result["final_answer"].lower(): 
            return "ACCEPTED"
        else:
            refinement_suggestion = check_result["refinement_suggestion"]
            # risk['hazard_check_log'] = check_result
            return f"REJECTED: {refinement_suggestion}"

def process_single_item(item, verifier, hazard_type):
    """
    å¤„ç†å•ä¸ªæ•°æ®é¡¹çš„é€»è¾‘å‡½æ•°
    """
    risk = item["safety_risk"]
    
    # è¿‡æ»¤æ¡ä»¶
    if risk is None or 'rejected' in risk['fidelity_check'].lower():
        return item, "Skipped (Fidelity)"

    image_path = os.path.join("data", risk["edit_image_path"])
    if not image_path or not os.path.exists(image_path):
        raise FileNotFoundError(f"Skipped (File not found: {image_path}")
        
    # å¤„ç†å›¾åƒ
    pil_image = Image.open(image_path).convert("RGB")
    objects_to_detect = []
    hazard_objs = risk["hazard_related_area"]

    # æ„å»ºæ£€æµ‹åˆ—è¡¨
    if hazard_type.lower() == "environmental":
        risk["bbox_annotation"] = {}
        # å‡è®¾ hazard_objs åœ¨ environmental ä¸‹æ˜¯åˆ—è¡¨
        for obj_name in hazard_objs:
            objects_to_detect.append(("hazard_area", obj_name))
    else:
        target_objs = hazard_objs.get("target_object", [])
        constraint_objs = hazard_objs.get("constraint_object", [])
        
        risk["bbox_annotation"] = {
            "target_object": {},
            "constraint_object": {}
        }
        if target_objs:
            for name in target_objs:
                objects_to_detect.append(("target_object", name))
        if constraint_objs:
            for name in constraint_objs:
                objects_to_detect.append(("constraint_object", name))

    # --- ç¬¬ä¸€æ­¥ï¼šæ ‡æ³¨ BBox ---
    risk["hazard_check"] = verifier.verify_object(image_path, pil_image, objects_to_detect, risk, hazard_type)

    # --- ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥ç©ºé—´å…³ç³» ---
    if risk["hazard_check"] == "ACCEPTED":
        risk["hazard_check"] = verifier.verify_state(pil_image, risk, hazard_type)
    
    return item, "Success"

def verify_hazard(meta_file_path, save_path, detector_name, hazard_type, max_workers):
    # if "qwen" in detector_name.lower():
    #     proxy_off()
    # else:
    #     proxy_on()
        
    # åˆå§‹åŒ–éªŒè¯å™¨
    # æ³¨æ„ï¼šå¦‚æœ HazardVerifier å†…éƒ¨æ¶‰åŠ GPU æ¨¡å‹ï¼Œè¯·ç¡®ä¿å®ƒæ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œ
    # æˆ–è€…å°† max_workers è®¾ç½®ä¸ºè¾ƒå°çš„å€¼ä»¥é˜²æ˜¾å­˜æº¢å‡ºã€‚
    verifier = HazardVerifier(detector_name)

    with open(meta_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    failed_items = []

    import ipdb; ipdb.set_trace()
    process_single_item(data[10], verifier, hazard_type)
    
    print(f"ğŸš€ Starting parallel processing with {max_workers} workers...")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_item = {
            executor.submit(process_single_item, item, verifier, hazard_type): i 
            for i, item in enumerate(data)
        }

        with tqdm(total=len(data), desc="ğŸ–¼ï¸ éªŒè¯å›¾åƒä¸­") as pbar:
            for future in as_completed(future_to_item):
                idx = future_to_item[future]
                try:
                    # è·å–ç»“æœï¼ˆitem ä¼šè¢«åŸä½ä¿®æ”¹ï¼Œå› ä¸ºå®ƒæ˜¯ mutable çš„ï¼‰
                    _, status = future.result()
                except Exception as e:
                    error_info = {"index": idx, "error": str(e)}
                    failed_items.append(error_info)
                    print(f"Error: {error_info}")
                finally:
                    pbar.update(1)

    # æ‰“å°é”™è¯¯æ‘˜è¦
    if failed_items:
        print(f"âš ï¸ Totally {len(failed_items)} failure case.")

    # ä¿å­˜ç»“æœ
    with open(save_path, "w", encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³: {save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--hazard_type',
        type=str,
        required=True,
        choices=['action_triggered', 'environmental'],
        help='Must be "action_triggered" or "environmental"'
    )
    parser.add_argument(
        '--detector_name',
        type=str,
        default="Qwen/Qwen3-VL-235B-A22B-Thinking",
    )
    parser.add_argument(
        '--max_workers',
        type=int,
        default=24,
    )
    args = parser.parse_args()
    meta_file_path = os.path.join("data", args.hazard_type, "annotation_info_pre.json")
    save_path = os.path.join("data", args.hazard_type, "annotation_info.json")
    save_folder = os.path.join("data", args.hazard_type, "annotate_image")
    if not os.path.exists(save_folder):
        os.mkdir(save_folder)
    verify_hazard(meta_file_path, save_path, args.detector_name, args.hazard_type, args.max_workers)